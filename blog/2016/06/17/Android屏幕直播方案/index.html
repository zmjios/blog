<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Android屏幕直播方案 · Eric's Blog</title><meta name="description" content="Android，视频，直播，WebSocket，FFmpeg，H.264"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="http://fonts.useso.com/css?family=Source+Sans+Pro:400,600" type="text/css"></head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="http://weibo.com/ele828" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://github.com/ele828" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">Android屏幕直播方案</h1><div class="post-info">Jun 17, 2016</div><div class="post-content"><p>项目需求是实时同步Android手机屏幕画面至浏览器。这里有两个挑战，一是Android如何在应用内获得屏幕实时视频流，另一个是如何在浏览器上做视频直播。经过一番折腾，确定了如下的实现方案。期间，我们也实现了手机摄像头的直播。</p>
<a id="more"></a>
<p>演示效果：</p>
<p><img src="/img/android-live-demo.gif" alt="演示"></p>
<h1 id="Android获取实时屏幕画面"><a href="#Android获取实时屏幕画面" class="headerlink" title="Android获取实时屏幕画面"></a>Android获取实时屏幕画面</h1><h2 id="原理与基础设置"><a href="#原理与基础设置" class="headerlink" title="原理与基础设置"></a>原理与基础设置</h2><p>Android 5.0版本之后，支持使用<code>MediaProjection</code>的方式获取屏幕视频流。具体的使用方法和原理如下图所示：</p>
<p><img src="/img/media-projection.png" alt="MediaProjection原理"></p>
<p>参考<strong>ScreenRecorder项目<sup>3</sup></strong>的实现，我们了解到<code>VirtualDisplay</code>可以获取当前屏幕的视频流，创建<code>VirtualDisplay</code>只需通过<code>MediaProjectionManager</code>获取<code>MediaProjection</code>，然后通过<code>MediaProjection</code>创建<code>VirtualDisplay</code>即可。</p>
<p>那么视频数据的流向是怎样的呢？</p>
<ul>
<li>首先，Display 会将画面投影到 VirtualDisplay中；</li>
<li>接着，VirtualDisplay 会将图像渲染到 Surface中，而这个Surface是由MediaCodec所创建的；</li>
<li>最后，用户可以通过MediaCodec获取特定编码的视频流数据。</li>
</ul>
<p>经过我们的尝试发现，在这个场景下，MediaCodec只允许使用<strong>video/avc</strong>编码类型，也就是<strong>RAW H.264</strong>的视频编码，使用其他的编码会出现应用Crash的现象（不知是否与硬件有关？）。由于这个视频编码，后面我们与它“搏斗”了好一段时间。</p>
<p>以下是关键部分的代码（来自<strong>ScreenRecorder项目<sup>3</sup></strong>）：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">codec = MediaCodec.createEncoderByType(MIME_TYPE);</span><br><span class="line">mSurface = codec.createInputSurface();</span><br><span class="line">mVirtualDisplay = mMediaProjection.createVirtualDisplay(</span><br><span class="line">		name,</span><br><span class="line">		mWidth,</span><br><span class="line">		mHeight,</span><br><span class="line">		mDpi,</span><br><span class="line">		DisplayManager.VIRTUAL_DISPLAY_FLAG_PUBLIC,</span><br><span class="line">		mSurface,    <span class="comment">// 图像会渲染到Surface中</span></span><br><span class="line">		<span class="keyword">null</span>,</span><br><span class="line">		<span class="keyword">null</span>);</span><br></pre></td></tr></table></figure>
<p>在编码之前，我们还需要设置视频编码的一些格式信息，这里我们通过<code>MediaFormat</code>进行编码格式设置，代码如下（来自<strong>ScreenRecorder项目<sup>3</sup></strong>）。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String MIME_TYPE = <span class="string">"video/avc"</span>; <span class="comment">// H.264编码</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> FRAME_RATE = <span class="number">30</span>;            <span class="comment">// 30 FPS</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> IFRAME_INTERVAL = <span class="number">10</span>;       <span class="comment">// I-frames间隔时间</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TIMEOUT_US = <span class="number">10000</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">prepareEncoder</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    MediaFormat format = MediaFormat.createVideoFormat(MIME_TYPE, mWidth, mHeight);</span><br><span class="line">    format.setInteger(MediaFormat.KEY_COLOR_FORMAT,</span><br><span class="line">            MediaCodecInfo.CodecCapabilities.COLOR_FormatSurface);</span><br><span class="line">    format.setInteger(MediaFormat.KEY_BIT_RATE, mBitRate);</span><br><span class="line">    format.setInteger(MediaFormat.KEY_FRAME_RATE, FRAME_RATE);</span><br><span class="line">    format.setInteger(MediaFormat.KEY_I_FRAME_INTERVAL, IFRAME_INTERVAL);</span><br><span class="line"></span><br><span class="line">    codec = MediaCodec.createEncoderByType(MIME_TYPE);</span><br><span class="line">    codec.configure(format, <span class="keyword">null</span>, <span class="keyword">null</span>, MediaCodec.CONFIGURE_FLAG_ENCODE);</span><br><span class="line">    codec.start();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="数据获取"><a href="#数据获取" class="headerlink" title="数据获取"></a>数据获取</h2><p><img src="/img/media-codec.png" alt="MediaCodec"></p>
<blockquote>
<p>图片来自Android官方文档</p>
</blockquote>
<p>紧接着，我们需要实时获取视频流了，我们可以直接从<code>MediaCodec</code>中获取视频数据。</p>
<p>根据官方文档，获取视频流有两种做法。一种是通过<strong>异步</strong>的方式获取数据，使用回调来获取<code>OutputBuffer</code>，具体代码详见<a href="https://developer.android.com/reference/android/media/MediaCodec.html" target="_blank" rel="external">Android文档</a>。</p>
<p>这里我们了解一下<strong>同步</strong>获取的方式，由于是同步执行，为了不阻塞主线程，必然需要启动一个新线程来处理。首先，程序会进入一个循环（可以设置变量进行停止），我们通过<code>codec.dequeueOutputBuffer()</code>方法获取到<code>outputBufferId</code>，接着通过ID获取<code>buffer</code>。这个<code>buffer</code>即是我们需要用到的<strong>实时视频帧数据</strong>了。代码如下（来自Android官方文档）：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">MediaFormat outputFormat = codec.getOutputFormat(); <span class="comment">// 方式二</span></span><br><span class="line">codec.start();</span><br><span class="line"><span class="keyword">for</span> (;;) &#123;</span><br><span class="line">  <span class="keyword">int</span> outputBufferId = codec.dequeueOutputBuffer(mBufferInfo, <span class="number">10000</span>);</span><br><span class="line">  <span class="keyword">if</span> (outputBufferId &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">    ByteBuffer outputBuffer = codec.getOutputBuffer(outputBufferId);</span><br><span class="line">    <span class="comment">// 方式一</span></span><br><span class="line">    MediaFormat bufferFormat = codec.getOutputFormat(outputBufferId);</span><br><span class="line">    codec.releaseOutputBuffer(outputBufferId, …);</span><br><span class="line">    </span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (outputBufferId == MediaCodec.INFO_OUTPUT_FORMAT_CHANGED) &#123;</span><br><span class="line">    outputFormat = codec.getOutputFormat(); <span class="comment">// 方式二</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">codec.stop();</span><br><span class="line">codec.release();</span><br></pre></td></tr></table></figure>
<p>按照<strong>ScreenRecorder项目<sup>3</sup></strong>的做法，接着他使用<code>MediaMuxer</code>的<code>Muxer.writeSampleData()</code>方法，直接将视频流<code>outputBuffer</code>写入了文件。</p>
<p>然而，我们需要的是实时推流至服务器。那么，接下去应该如何实现呢？</p>
<h2 id="视频推流"><a href="#视频推流" class="headerlink" title="视频推流"></a>视频推流</h2><p>这里有一个小插曲，为了完成这个项目，我和同学查阅了不少资料和源码。其中有一个<strong>RtmpRecoder项目<sup>2</sup></strong>使用<code>FFmpeg</code>进行实时摄像头的<code>RTMP</code>推流，推流的原理如下图所示。</p>
<p><img src="/img/ffmpeg-push.jpg" alt="FFmpeg推流"></p>
<p><a href="https://ffmpeg.org/" target="_blank" rel="external">FFmpeg</a>是一个大名鼎鼎的音视频转码库，它由C语言实现，因此在Java中，我们需要通过JNI进行调用，这里，我们使用了<strong>JavaCV<sup>1</sup></strong>的FFmpeg转码功能。</p>
<div class="tip"><br>注意：如果使用JavaCV并采用<code>mpeg1video</code>格式推流至服务器，切记将声道调为0，<code>recorder.setAudioChannels(0)</code>，否则视频会残缺不全。<br></div>

<p>说到这里，不得不吐槽一下<strong>JavaCV<sup>1</sup></strong>，它没有文档，没有文档是件很可怕的事情，编程基本靠猜。而且它也没有实现FFmpeg的全部功能！！！我们为了把获取到的<strong>视频帧</strong>流数据传给JavaCV费了好大功夫，曾经一度想通过调用C语言函数来完成这项工作，但没有成功！</p>
<p>到最后黔驴技穷，只好去项目中开Issue寻求帮助，然而作者表示尚未实现该功能，WTF。好吧，毕竟开源项目，别人也没有义务去做这件事。所以最后也只能自己来解决这个问题了。</p>
<p><img src="/img/javacv-issue.png" alt=""></p>
<p>废话不多说，既然<strong>JavaCV<sup>1</sup></strong>无法完成这项工作，那么我们只好另辟蹊径。</p>
<p>现在，有两种做法。</p>
<ul>
<li>自己编写FFmpeg类库。我尝试直接使用CLI接入stream的方式实现实时推流。方法也很简单，只需要在Java中启动<code>FFmpeg</code>进程，然后pipe输入流，再由<code>FFmpeg</code>推流至服务器。但实践之后发现一些奇怪的问题，只好作罢。</li>
<li>另一个方案就是徒手来处理<strong>视频帧</strong>数据，将转码的工作放到服务器端去实现，最后我们使用这个方案成功完成了任务。下面来看看H.264编码：</li>
</ul>
<h1 id="H-264编码"><a href="#H-264编码" class="headerlink" title="H.264编码"></a>H.264编码</h1><p>众所周知，视频编码格式种类繁多，H.264也是其中一种编码，每一种编码都有其特点和适用场景，更多信息请自行搜索，这里不多做赘述。期间，我们尝试过将上面获取到的<strong>视频帧</strong>数据保存为文件，想研究视频文件为什么会呈现为<strong>绿屏</strong>的画面。经过翻阅资料和试验我们发现，<strong>H.264</strong>编码有着特殊的分层结构。</p>
<blockquote>
<p>H.264 的功能分为两层：视频编码层(VCL, Video Coding Layer)和网络提取层(NAL, Network Abstraction Layer)。VCL 数据即编码处理的输出，它表示被压缩编码后的视频数据 序列。在 VCL 数据传输或存储之前,这些编码的 VCL 数据，先被映射或封装进 NAL 单元中。每个 NAL 单元包括一个原始字节序列负荷(RBSP, Raw Byte Sequence Payload)、一组对应于视频编码的 NAL 头信息。RBSP 的基本结构是：在原始编码数据的后面填加了结尾比特。一个bit“1”若干比特“0”，以便字节对齐。</p>
</blockquote>
<p><img src="/img/nal.png" alt="NAL"></p>
<p>因此，为了将帧序列变成合法的H.264编码，我们需要手动构建<strong>NAL单元</strong>。H.264的帧是以<strong>NAL单元</strong>为单位进行封装的，NAL单元的结构如上图所示。H.264分为<code>Annexb</code>和<code>RTP</code>两种格式，<code>RTP</code>格式更适合用于网络传输，因为其结构更加节省空间，但由于Android系统提供的数据本身就是<code>Annexb</code>格式的，因此我们采用<code>Annexb</code>格式进行传输。</p>
<p>按照<code>Annexb</code>格式的要求，我们需要将数据封装为如下格式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0000 0001 + SPS + 0000 0001 + PPS + 0000 0001 + 视频帧（IDR帧）</span><br></pre></td></tr></table></figure>
<blockquote>
<p>H.264的SPS和PPS串，包含了初始化H.264解码器所需要的信息参数，包括编码所用的profile，level，图像的宽和高，deblock滤波器等。</p>
</blockquote>
<p>然后不断重复以上格式即可输出正确的<strong>H.264</strong>编码的视频流了。这里的SPS和PPS在每一个NAL单元中重复存在，主要是适用于流式传播的场景，设想一下如果流式传播过程中漏掉了开头的SPS和PPS，那么整个视频流将永远无法被正确解码。</p>
<p>我们在实践过程中，SPS和PPS只传递了一次，这样的方式比较适合我们的项目场景，也比较省流量。因此在我们的方案中，格式变为如下形式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0000 0001 + SPS + 0000 0001 + PPS + 0000 0001 + 视频帧（IDR帧）+ 0000 0001 + 视频帧 + ...</span><br></pre></td></tr></table></figure>
<p>H.264编码比较复杂，我也只是在做项目期间查阅一些资料才有一点大概的了解，然后在项目完成之后才去反思和理解背后的原理。如果要深入学习，可以查阅相关的资料（<strong>H.264视频压缩标准<sup>5</sup></strong>）。</p>
<p>介绍完<strong>H.264</strong>的基本原理，下面看看Android上具体的实现。其实Android系统的<code>MediaCodec</code>类库已经帮助我们完成了较多的工作，我们只需要在开始录制时（或每一次传输视频帧前）在视频帧之前写入SPS和PPS信息即可。<code>MediaCodec</code>已经默认在数据流（视频帧和SPS、PPS）之前添加了<code>start code</code>(0x01)，我们不需要手动填写。</p>
<p>SPS和PPS分别对应了<code>bufferFormat</code>中的<code>csd-0</code>和<code>csd-1</code>字段。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (outputBufferId == MediaCodec.INFO_OUTPUT_FORMAT_CHANGED) &#123;</span><br><span class="line">	MediaFormat outputFormat = codec.getOutputFormat();</span><br><span class="line">	outputFormat.getByteBuffer(<span class="string">"csd-0"</span>);    <span class="comment">// SPS</span></span><br><span class="line">	outputFormat.getByteBuffer(<span class="string">"csd-1"</span>);    <span class="comment">// PPS</span></span><br><span class="line">	<span class="comment">/* 然后直接写入传输流 */</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="服务器端"><a href="#服务器端" class="headerlink" title="服务器端"></a>服务器端</h1><p>实时的数据流通过Socket(tcp)传输到服务器端，服务器端采用<code>Node.js</code>实现视频流转码和<code>WebSocket</code>转播。为了使前端可以播放实时的视频，我们必须将格式转换为前端支持的视频格式，这里解码使用<code>FFmpeg</code>的Node.js封装（<strong>stream-transcoder项目<sup>6</sup></strong>）。以下是Socket通讯和转码的关键代码：</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> Transcoder = <span class="built_in">require</span>(<span class="string">'stream-transcoder'</span>);</span><br><span class="line"><span class="keyword">var</span> net = <span class="built_in">require</span>(<span class="string">'net'</span>);</span><br><span class="line"></span><br><span class="line">net.createServer(<span class="function"><span class="keyword">function</span>(<span class="params">sock</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">    sock.on(<span class="string">'close'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">data</span>) </span>&#123;</span><br><span class="line">        <span class="built_in">console</span>.log(<span class="string">'CLOSED: '</span> +</span><br><span class="line">            sock.remoteAddress + <span class="string">' '</span> + sock.remotePort);</span><br><span class="line">    &#125;);</span><br><span class="line"></span><br><span class="line">    sock.on(<span class="string">'error'</span>, (err) =&gt; &#123;</span><br><span class="line">        <span class="built_in">console</span>.log(err)</span><br><span class="line">    &#125;);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 转码  H.264 =&gt; mpeg1video</span></span><br><span class="line">    <span class="keyword">new</span> Transcoder(sock)</span><br><span class="line">      .size(width, height)</span><br><span class="line">      .fps(<span class="number">30</span>)</span><br><span class="line">      .videoBitrate(<span class="number">500</span> * <span class="number">1000</span>)</span><br><span class="line">      .format(<span class="string">'mpeg1video'</span>)</span><br><span class="line">      .channels(<span class="number">0</span>)</span><br><span class="line">      .stream()</span><br><span class="line">      .on(<span class="string">'data'</span>, <span class="function"><span class="keyword">function</span>(<span class="params">data</span>) </span>&#123;</span><br><span class="line">        <span class="comment">// WebSocket转播</span></span><br><span class="line">        socketServer.broadcast(data, &#123;binary:<span class="literal">true</span>&#125;);</span><br><span class="line">      &#125;)</span><br><span class="line"></span><br><span class="line">&#125;).listen(<span class="number">9091</span>);</span><br></pre></td></tr></table></figure>
<h1 id="Web直播"><a href="#Web直播" class="headerlink" title="Web直播"></a>Web直播</h1><p>紧接着，Web前端与服务器建立<code>WebSocket</code>连接，使用<strong>jsmpeg项目<sup>7</sup></strong>对mpeg1video的视频流进行解码并呈现在Canvas上。</p>
<figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> client = <span class="keyword">new</span> WebSocket(<span class="string">'ws://127.0.0.1:9092/'</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> canvas = <span class="built_in">document</span>.getElementById(<span class="string">'videoCanvas'</span>);</span><br><span class="line"><span class="keyword">var</span> player = <span class="keyword">new</span> jsmpeg(client, &#123;canvas:canvas&#125;);</span><br></pre></td></tr></table></figure>
<p>后续还可以做一些灵活的配置以及错误处理，可以让整个直播的流程更加稳定。至于视频方面的优化，也可以继续尝试各种参数的调节等等。</p>
<p>为了完成这个项目，我们前后花费了四五天的时间，进行各种摸索和尝试，所以我决定记录下这个方案，希望可以帮到有需要的人。</p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><ol>
<li>参考<a href="https://github.com/bytedeco/javacv" target="_blank" rel="external">JavaCV</a>项目</li>
<li>参考<a href="https://github.com/beautifulSoup/RtmpRecoder" target="_blank" rel="external">RtmpRecoder开源项目</a>的实现</li>
<li>参考<a href="https://github.com/yrom/ScreenRecorder" target="_blank" rel="external">ScreenRecorder开源项目</a>的实现</li>
<li>参考<a href="https://developer.android.com/reference/android/media/MediaCodec.html" target="_blank" rel="external">Android文档</a></li>
<li>文献<a href="http://www.axis.com/files/whitepaper/wp_h264_34203_cn_0901_lo.pdf" target="_blank" rel="external">H.264视频压缩标准</a></li>
<li>使用<a href="https://github.com/trenskow/stream-transcoder.js" target="_blank" rel="external">stream-transcoder项目</a></li>
<li>使用<a href="https://github.com/phoboslab/jsmpeg" target="_blank" rel="external">jsmpeg项目</a></li>
</ol>
</div></article></div></section><footer><div class="paginator"><a href="/blog/2016/06/16/北美实习求职记(一)/" class="next">NEXT</a></div><div id="disqus_thread"></div><script>var disqus_shortname = 'ele828';
var disqus_identifier = 'blog/2016/06/17/Android屏幕直播方案/';
var disqus_title = 'Android屏幕直播方案';
var disqus_url = 'http://www.dobest.me/blog/2016/06/17/Android屏幕直播方案/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//ele828.disqus.com/count.js" async></script><div class="copyright"><p>© 2015 - 2016 <a href="http://www.dobest.me">Eric Wong</a>, unless otherwise noted.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"UA-79167899-1",'auto');ga('send','pageview');</script></body></html>